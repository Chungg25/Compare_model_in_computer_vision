# Comparison of Deep Learning Models in Computer Vision

## Overview

This project compares five prominent deep learning models in computer vision, analyzing their theoretical foundations, practical implementations, and performance across various tasks:

1. **Convolutional Neural Networks (CNNs)**
2. **Mask R-CNN**
3. **AutoEncoder**
4. **DCGAN**
5. **Vision Transformer (ViT)**

The analysis highlights the strengths and limitations of each model to provide insights into their suitability for different applications in computer vision.

## Models Overview

### 1. **Convolutional Neural Networks (CNNs)**

-   **Applications**: Image classification, object detection.
-   **Strengths**: Excellent for structured data, hierarchical feature extraction.
-   **Limitations**: Requires large datasets, computationally expensive.

### 2. **Mask R-CNN**

-   **Applications**: Instance segmentation.
-   **Strengths**: High accuracy in detecting and segmenting objects.
-   **Limitations**: Computational overhead.

### 3. **AutoEncoder**

-   **Applications**: Dimensionality reduction, anomaly detection.
-   **Variants**: Denoising AutoEncoder, Variational AutoEncoder.
-   **Limitations**: Prone to overfitting.

### 4. **DCGAN**

-   **Applications**: Image generation.
-   **Strengths**: Generates high-quality synthetic data.
-   **Challenges**: Stability during training.

### 5. **Vision Transformer (ViT)**

-   **Applications**: Image classification.
-   **Strengths**: Efficient in capturing global context.
-   **Limitations**: Needs large datasets for training.

## Usage Instructions

Detailed usage instructions for running each model, including dataset preparation and evaluation steps, are available in the project source directory.

**Refer to the usage guide here**: [Usage Instructions](source/README.md)

## Authors

-   **Hà Trọng Nguyễn**
-   **Chung Thái Kiệt**

This project was conducted as part of the Midterm Report for the "Introduction to Computer Vision" course at Tôn Đức Thắng University, Ho Chi Minh City, Vietnam, 2024.
